{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Conditional SMILES Generation Using a GPT Model\n",
    "\n",
    "**Author:** Mahmoud Ebrahimkhani \n",
    "\n",
    "**Date:** 2025-04-11\n",
    "\n",
    "**Course:** Applied Deep Learning and Generative AI in Healthcare\n",
    "\n",
    "**Reference:** DOI: [10.1021/acs.jcim.1c00600](https://doi.org/10.1021/acs.jcim.1c00600)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you will train transformer-based language model to design novel drug-like small molecules. We'll walk through an end-to-end pipeline where a GPT-style model (decoder-only transformer) is trained to generate valid SMILES (Simplified Molecular Input Line Entry System) strings, *conditioned on desired molecular properties*. These properties—such as scaffold, LogP, QED, and TPSA are relevant in early drug discovery for assessing bioavailability, drug-likeness, and molecular complexity.\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Do\n",
    "\n",
    "1. **Load and explore** the MOSES dataset ([github.com/molecularsets/moses](https://github.com/molecularsets/moses)), which contains pre-filtered drug-like molecules.\n",
    "2. **Compute molecular descriptors**, including:\n",
    "    - Scaffold (core structure of a molecule): The rigid, central framework that defines the molecule's basic shape and connectivity.\n",
    "    - LogP (lipophilicity): A measure of how well a molecule dissolves in fats versus water, important for drug absorption and distribution.\n",
    "    - QED (quantitative estimate of drug-likeness): A score between 0 and 1 that indicates how similar a molecule's properties are to known drugs.\n",
    "    - TPSA (topological polar surface area): The total surface area of all polar atoms (mainly oxygen and nitrogen) in the molecule, which helps predict drug absorption.\n",
    "3. **Format the data** to enable *conditional* generation—so the model learns to generate SMILES strings based on specified property values.\n",
    "4. **Train a GPT-like transformer model** to generate molecules.\n",
    "5. **Evaluate the quality of the generated molecules** using:\n",
    "    - Validity of SMILES strings: Using RDKit to parse each generated SMILES string and verify it represents a valid chemical structure\n",
    "    - Uniqueness of generated molecules: Computing the ratio of unique SMILES strings to total generated molecules\n",
    "    - Tanimoto similarity to training molecules: Calculating molecular fingerprint similarity between generated and training set molecules to assess novelty\n",
    "    - Alignment with the conditional property distributions: Comparing statistical distributions of properties (LogP, QED, TPSA) between generated and training molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "You may need to install a few dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install rdkit-pypi transformers torch tqdm scikit-learn matplotlib moses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors, QED\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import GetScaffoldForMol\n",
    "from rdkit.Chem import rdDecomposition, rdMolDescriptors, rdDistGeom\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2Config,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "from moses.dataset import get_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
